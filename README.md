# Project--ML-18


<table>


**In this project we will build the Upper Confidence Bound for analysis of click rates of different ad and selecting the best ads among all**.<br></br>  

In Reinforcement Learning, we use Multi-Armed Bandit Problem to formalize the notion of decision-making under uncertainty using k-armed bandits. A decision-maker or agent is present in Multi-Armed Bandit Problem to choose between k-different actions and receives a reward based on the action it chooses.
Bandit problem is used to describe fundamental concepts in reinforcement learning, such as rewards, timesteps, and values.<br></br>
Upper-Confidence Bound action selection uses uncertainty in the action-value estimates for balancing exploration and exploitation.
Since there is inherent uncertainty in the accuracy of the action-value estimates when we use a sampled set of rewards thus UCB uses uncertainty in the estimates to drive exploration.<br></br>
The Upper Confidence Bound follows the principle of optimism in the face of uncertainty which implies that if we are uncertain about an action, we should optimistically assume that it is the correct action.<br></br>


  
**Important- Note: Explore the dataset once before going through the code.**
</table>

**So what are you waiting for...? Jump to the code to get started. As usual for any doubt or query see you in pull request section üòÅüòÇ. Thanks!**

